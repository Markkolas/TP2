{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markkolas/TP2/blob/jorge-test/Final_corregido/virtualenv_Sparseml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHYvfHuly9Y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd158f4d-273d-46ff-cd37-5461fb85d8c7"
      },
      "source": [
        "!pip3 install virtualenv\n",
        "!virtualenv theanoEnv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.23.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.3.0)\n",
            "created virtual environment CPython3.10.11.final.0-64 in 481ms\n",
            "  creator CPython3Posix(dest=/content/theanoEnv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: GPUtil==1.4.0, Jinja2==3.1.2, Markdown==3.4.3, MarkupSafe==2.1.2, Pillow==9.5.0, PyWavelets==1.4.1, PyYAML==6.0, Pygments==2.15.1, QtPy==2.3.1, Send2Trash==1.8.2, Theano==1.0.5, Werkzeug==2.3.4, absl_py==1.4.0, anyio==3.7.0, argon2_cffi==21.3.0, argon2_cffi_bindings==21.2.0, arrow==1.2.3, asttokens==2.2.1, attrs==23.1.0, backcall==0.2.0, beautifulsoup4==4.12.2, bleach==6.0.0, cachetools==5.3.1, certifi==2023.5.7, cffi==1.15.1, charset_normalizer==3.1.0, click==8.0.4, comm==0.1.3, contourpy==1.0.7, cycler==0.11.0, debugpy==1.6.7, decorator==5.1.1, defusedxml==0.7.1, exceptiongroup==1.1.1, executing==1.2.0, fastjsonschema==2.17.1, fonttools==4.39.4, fqdn==1.5.1, google_auth==2.19.0, google_auth_oauthlib==1.0.0, gputils==1.0.6, grpcio==1.54.2, idna==3.4, imageio==2.29.0, ipykernel==6.23.1, ipython==8.12.0, ipython_genutils==0.2.0, ipywidgets==8.0.6, isoduration==20.11.0, jedi==0.18.2, joblib==1.2.0, jsonpointer==2.3, jsonschema==4.17.3, jupyter==1.0.0, jupyter_client==8.2.0, jupyter_console==6.6.3, jupyter_core==5.3.0, jupyter_events==0.6.3, jupyter_server==2.6.0, jupyter_server_terminals==0.4.4, jupyterlab_pygments==0.2.2, jupyterlab_widgets==3.0.7, kiwisolver==1.4.4, lazy_loader==0.2, matplotlib==3.7.1, matplotlib_inline==0.1.6, merge_args==0.1.5, mistune==2.0.5, nbclassic==1.0.0, nbclient==0.8.0, nbconvert==7.4.0, nbformat==5.8.0, nest_asyncio==1.5.6, networkx==3.1, notebook==6.5.4, notebook_shim==0.2.3, numpy==1.21.6, oauthlib==3.2.2, onnx==1.12.0, opencv_python==4.6.0.66, overrides==7.3.1, packaging==23.1, pandas==2.0.1, pandocfilters==1.5.0, parso==0.8.3, pexpect==4.8.0, pickleshare==0.7.5, pip==23.1.2, platformdirs==3.5.1, progressbar2==4.2.0, prometheus_client==0.17.0, prompt_toolkit==3.0.38, protobuf==3.20.1, psutil==5.9.5, ptyprocess==0.7.0, pure_eval==0.2.2, pyasn1==0.5.0, pyasn1_modules==0.3.0, pycparser==2.21, pydantic==1.10.8, pyparsing==3.0.9, pyrsistent==0.19.3, python_dateutil==2.8.2, python_json_logger==2.0.7, python_utils==3.5.2, pytz==2023.3, pyzmq==25.1.0, qtconsole==5.4.3, requests==2.31.0, requests_oauthlib==1.3.1, rfc3339_validator==0.1.4, rfc3986_validator==0.1.1, rsa==4.9, scikit_image==0.20.0, scikit_learn==1.2.2, scipy==1.10.1, seaborn==0.12.2, setuptools==67.7.2, six==1.16.0, sniffio==1.3.0, soupsieve==2.4.1, sparseml==1.4.4, sparsezoo==1.4.0, stack_data==0.6.2, tensorboard==2.13.0, tensorboard_data_server==0.7.0, terminado==0.17.1, thop==0.1.1.post2209072238, threadpoolctl==3.1.0, tifffile==2023.4.12, tinycss2==1.2.1, toposort==1.10, torch==1.12.0, torchvision==0.13.0, tornado==6.3.2, tqdm==4.65.0, traitlets==5.9.0, typing_extensions==4.6.2, tzdata==2023.3, uri_template==1.2.0, urllib3==1.26.16, wcwidth==0.2.6, webcolors==1.13, webencodings==0.5.1, websocket_client==1.5.2, wheel==0.40.0, widgetsnbextension==4.0.7, yolov5==6.2.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ZquFUszJD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620b875d-6be9-4d82-8412-12c81f63a513"
      },
      "source": [
        "!source /content/theanoEnv/bin/activate; pip3 install theano"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: theano in ./theanoEnv/lib/python3.10/site-packages (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in ./theanoEnv/lib/python3.10/site-packages (from theano) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.14 in ./theanoEnv/lib/python3.10/site-packages (from theano) (1.10.1)\n",
            "Requirement already satisfied: six>=1.9.0 in ./theanoEnv/lib/python3.10/site-packages (from theano) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a7lA-T3zgXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235a28c0-3bbb-42ce-9cb7-e6ce564b6797"
      },
      "source": [
        "!source /content/theanoEnv/bin/activate; pip3 list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                  Version\n",
            "------------------------ --------------------\n",
            "absl-py                  1.4.0\n",
            "anyio                    3.7.0\n",
            "argon2-cffi              21.3.0\n",
            "argon2-cffi-bindings     21.2.0\n",
            "arrow                    1.2.3\n",
            "asttokens                2.2.1\n",
            "attrs                    23.1.0\n",
            "backcall                 0.2.0\n",
            "beautifulsoup4           4.12.2\n",
            "bleach                   6.0.0\n",
            "cachetools               5.3.1\n",
            "certifi                  2023.5.7\n",
            "cffi                     1.15.1\n",
            "charset-normalizer       3.1.0\n",
            "click                    8.0.4\n",
            "comm                     0.1.3\n",
            "contourpy                1.0.7\n",
            "cycler                   0.11.0\n",
            "debugpy                  1.6.7\n",
            "decorator                5.1.1\n",
            "defusedxml               0.7.1\n",
            "exceptiongroup           1.1.1\n",
            "executing                1.2.0\n",
            "fastjsonschema           2.17.1\n",
            "fonttools                4.39.4\n",
            "fqdn                     1.5.1\n",
            "google-auth              2.19.0\n",
            "google-auth-oauthlib     1.0.0\n",
            "GPUtil                   1.4.0\n",
            "gputils                  1.0.6\n",
            "grpcio                   1.54.2\n",
            "idna                     3.4\n",
            "imageio                  2.29.0\n",
            "ipykernel                6.23.1\n",
            "ipython                  8.12.0\n",
            "ipython-genutils         0.2.0\n",
            "ipywidgets               8.0.6\n",
            "isoduration              20.11.0\n",
            "jedi                     0.18.2\n",
            "Jinja2                   3.1.2\n",
            "joblib                   1.2.0\n",
            "jsonpointer              2.3\n",
            "jsonschema               4.17.3\n",
            "jupyter                  1.0.0\n",
            "jupyter_client           8.2.0\n",
            "jupyter-console          6.6.3\n",
            "jupyter_core             5.3.0\n",
            "jupyter-events           0.6.3\n",
            "jupyter_server           2.6.0\n",
            "jupyter_server_terminals 0.4.4\n",
            "jupyterlab-pygments      0.2.2\n",
            "jupyterlab-widgets       3.0.7\n",
            "kiwisolver               1.4.4\n",
            "lazy_loader              0.2\n",
            "Markdown                 3.4.3\n",
            "MarkupSafe               2.1.2\n",
            "matplotlib               3.7.1\n",
            "matplotlib-inline        0.1.6\n",
            "merge-args               0.1.5\n",
            "mistune                  2.0.5\n",
            "nbclassic                1.0.0\n",
            "nbclient                 0.8.0\n",
            "nbconvert                7.4.0\n",
            "nbformat                 5.8.0\n",
            "nest-asyncio             1.5.6\n",
            "networkx                 3.1\n",
            "notebook                 6.5.4\n",
            "notebook_shim            0.2.3\n",
            "numpy                    1.21.6\n",
            "oauthlib                 3.2.2\n",
            "onnx                     1.12.0\n",
            "opencv-python            4.6.0.66\n",
            "overrides                7.3.1\n",
            "packaging                23.1\n",
            "pandas                   2.0.1\n",
            "pandocfilters            1.5.0\n",
            "parso                    0.8.3\n",
            "pexpect                  4.8.0\n",
            "pickleshare              0.7.5\n",
            "Pillow                   9.5.0\n",
            "pip                      23.1.2\n",
            "platformdirs             3.5.1\n",
            "progressbar2             4.2.0\n",
            "prometheus-client        0.17.0\n",
            "prompt-toolkit           3.0.38\n",
            "protobuf                 3.20.1\n",
            "psutil                   5.9.5\n",
            "ptyprocess               0.7.0\n",
            "pure-eval                0.2.2\n",
            "pyasn1                   0.5.0\n",
            "pyasn1-modules           0.3.0\n",
            "pycparser                2.21\n",
            "pydantic                 1.10.8\n",
            "Pygments                 2.15.1\n",
            "pyparsing                3.0.9\n",
            "pyrsistent               0.19.3\n",
            "python-dateutil          2.8.2\n",
            "python-json-logger       2.0.7\n",
            "python-utils             3.5.2\n",
            "pytz                     2023.3\n",
            "PyWavelets               1.4.1\n",
            "PyYAML                   6.0\n",
            "pyzmq                    25.1.0\n",
            "qtconsole                5.4.3\n",
            "QtPy                     2.3.1\n",
            "requests                 2.31.0\n",
            "requests-oauthlib        1.3.1\n",
            "rfc3339-validator        0.1.4\n",
            "rfc3986-validator        0.1.1\n",
            "rsa                      4.9\n",
            "scikit-image             0.20.0\n",
            "scikit-learn             1.2.2\n",
            "scipy                    1.10.1\n",
            "seaborn                  0.12.2\n",
            "Send2Trash               1.8.2\n",
            "setuptools               67.7.2\n",
            "six                      1.16.0\n",
            "sniffio                  1.3.0\n",
            "soupsieve                2.4.1\n",
            "sparseml                 1.4.4\n",
            "sparsezoo                1.4.0\n",
            "stack-data               0.6.2\n",
            "tensorboard              2.13.0\n",
            "tensorboard-data-server  0.7.0\n",
            "terminado                0.17.1\n",
            "Theano                   1.0.5\n",
            "thop                     0.1.1.post2209072238\n",
            "threadpoolctl            3.1.0\n",
            "tifffile                 2023.4.12\n",
            "tinycss2                 1.2.1\n",
            "toposort                 1.10\n",
            "torch                    1.12.0\n",
            "torchvision              0.13.0\n",
            "tornado                  6.3.2\n",
            "tqdm                     4.65.0\n",
            "traitlets                5.9.0\n",
            "typing_extensions        4.6.2\n",
            "tzdata                   2023.3\n",
            "uri-template             1.2.0\n",
            "urllib3                  1.26.16\n",
            "wcwidth                  0.2.6\n",
            "webcolors                1.13\n",
            "webencodings             0.5.1\n",
            "websocket-client         1.5.2\n",
            "Werkzeug                 2.3.4\n",
            "wheel                    0.40.0\n",
            "widgetsnbextension       4.0.7\n",
            "yolov5                   6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; pip3 install sparseml[torchvision]; pip3 list"
      ],
      "metadata": {
        "id": "x4PzROPt6gjo",
        "outputId": "e9ad038f-3375-4d33-8258-4844a6fc02a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sparseml[torchvision] in ./theanoEnv/lib/python3.10/site-packages (1.4.4)\n",
            "Requirement already satisfied: sparsezoo~=1.4.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.4.0)\n",
            "Collecting setuptools<=59.5.0 (from sparseml[torchvision])\n",
            "  Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "Requirement already satisfied: jupyter>=1.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (8.0.6)\n",
            "Requirement already satisfied: pyyaml>=5.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (6.0)\n",
            "Requirement already satisfied: progressbar2>=3.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (4.2.0)\n",
            "Requirement already satisfied: numpy<=1.21.6,>=1.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (3.7.1)\n",
            "Requirement already satisfied: merge-args>=0.1.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (0.1.5)\n",
            "Requirement already satisfied: onnx<=1.12.0,>=1.5.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.25.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (2.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (23.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=1.5.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.10.8)\n",
            "Requirement already satisfied: requests>=2.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (2.31.0)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (0.20.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.10.1)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (4.65.0)\n",
            "Requirement already satisfied: toposort>=1.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.10)\n",
            "Requirement already satisfied: GPUtil>=1.4.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.4.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (3.20.1)\n",
            "Requirement already satisfied: click~=8.0.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (8.0.4)\n",
            "Requirement already satisfied: torch<=1.12.1,>=1.1.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.12.0)\n",
            "Requirement already satisfied: gputils in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (1.0.6)\n",
            "Requirement already satisfied: torchvision<=0.13,>=0.3.0 in ./theanoEnv/lib/python3.10/site-packages (from sparseml[torchvision]) (0.13.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in ./theanoEnv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->sparseml[torchvision]) (6.23.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in ./theanoEnv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->sparseml[torchvision]) (8.12.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in ./theanoEnv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->sparseml[torchvision]) (5.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.7 in ./theanoEnv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->sparseml[torchvision]) (4.0.7)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in ./theanoEnv/lib/python3.10/site-packages (from ipywidgets>=7.0.0->sparseml[torchvision]) (3.0.7)\n",
            "Requirement already satisfied: notebook in ./theanoEnv/lib/python3.10/site-packages (from jupyter>=1.0.0->sparseml[torchvision]) (6.5.4)\n",
            "Requirement already satisfied: qtconsole in ./theanoEnv/lib/python3.10/site-packages (from jupyter>=1.0.0->sparseml[torchvision]) (5.4.3)\n",
            "Requirement already satisfied: jupyter-console in ./theanoEnv/lib/python3.10/site-packages (from jupyter>=1.0.0->sparseml[torchvision]) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in ./theanoEnv/lib/python3.10/site-packages (from jupyter>=1.0.0->sparseml[torchvision]) (7.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (4.39.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./theanoEnv/lib/python3.10/site-packages (from matplotlib>=3.0.0->sparseml[torchvision]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./theanoEnv/lib/python3.10/site-packages (from onnx<=1.12.0,>=1.5.0->sparseml[torchvision]) (4.6.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./theanoEnv/lib/python3.10/site-packages (from pandas>=0.25.0->sparseml[torchvision]) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./theanoEnv/lib/python3.10/site-packages (from pandas>=0.25.0->sparseml[torchvision]) (2023.3)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in ./theanoEnv/lib/python3.10/site-packages (from progressbar2>=3.0.0->sparseml[torchvision]) (3.5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./theanoEnv/lib/python3.10/site-packages (from requests>=2.0.0->sparseml[torchvision]) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./theanoEnv/lib/python3.10/site-packages (from requests>=2.0.0->sparseml[torchvision]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./theanoEnv/lib/python3.10/site-packages (from requests>=2.0.0->sparseml[torchvision]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./theanoEnv/lib/python3.10/site-packages (from requests>=2.0.0->sparseml[torchvision]) (2023.5.7)\n",
            "Requirement already satisfied: networkx>=2.8 in ./theanoEnv/lib/python3.10/site-packages (from scikit-image>=0.15.0->sparseml[torchvision]) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in ./theanoEnv/lib/python3.10/site-packages (from scikit-image>=0.15.0->sparseml[torchvision]) (2.29.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in ./theanoEnv/lib/python3.10/site-packages (from scikit-image>=0.15.0->sparseml[torchvision]) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in ./theanoEnv/lib/python3.10/site-packages (from scikit-image>=0.15.0->sparseml[torchvision]) (1.4.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in ./theanoEnv/lib/python3.10/site-packages (from scikit-image>=0.15.0->sparseml[torchvision]) (0.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in ./theanoEnv/lib/python3.10/site-packages (from scikit-learn>=0.24.2->sparseml[torchvision]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./theanoEnv/lib/python3.10/site-packages (from scikit-learn>=0.24.2->sparseml[torchvision]) (3.1.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (0.1.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (1.6.7)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (8.2.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (5.3.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (1.5.6)\n",
            "Requirement already satisfied: pyzmq>=20 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (25.1.0)\n",
            "Requirement already satisfied: tornado>=6.1 in ./theanoEnv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (6.3.2)\n",
            "Requirement already satisfied: backcall in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.2.0)\n",
            "Requirement already satisfied: decorator in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (3.0.38)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (2.15.1)\n",
            "Requirement already satisfied: stack-data in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in ./theanoEnv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in ./theanoEnv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->sparseml[torchvision]) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (4.12.2)\n",
            "Requirement already satisfied: bleach in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (3.1.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (0.2.2)\n",
            "Requirement already satisfied: markupsafe>=2.0 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (2.1.2)\n",
            "Requirement already satisfied: mistune<3,>=2.0.3 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (2.0.5)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (0.8.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (5.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in ./theanoEnv/lib/python3.10/site-packages (from nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (21.3.0)\n",
            "Requirement already satisfied: ipython-genutils in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.17.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in ./theanoEnv/lib/python3.10/site-packages (from notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.0.0)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in ./theanoEnv/lib/python3.10/site-packages (from qtconsole->jupyter>=1.0.0->sparseml[torchvision]) (2.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./theanoEnv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./theanoEnv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->sparseml[torchvision]) (3.5.1)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in ./theanoEnv/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (2.6.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in ./theanoEnv/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in ./theanoEnv/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in ./theanoEnv/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (4.17.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./theanoEnv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./theanoEnv/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.2.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in ./theanoEnv/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torchvision]) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./theanoEnv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (2.4.1)\n",
            "Requirement already satisfied: webencodings in ./theanoEnv/lib/python3.10/site-packages (from bleach->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (0.5.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./theanoEnv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./theanoEnv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in ./theanoEnv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.0.0->sparseml[torchvision]) (0.2.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (0.19.3)\n",
            "Requirement already satisfied: anyio>=3.1.0 in ./theanoEnv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (3.7.0)\n",
            "Requirement already satisfied: jupyter-events>=0.6.0 in ./theanoEnv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.6.3)\n",
            "Requirement already satisfied: jupyter-server-terminals in ./theanoEnv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.4.4)\n",
            "Requirement already satisfied: overrides in ./theanoEnv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (7.3.1)\n",
            "Requirement already satisfied: websocket-client in ./theanoEnv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.5.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in ./theanoEnv/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.15.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./theanoEnv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in ./theanoEnv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (1.1.1)\n",
            "Requirement already satisfied: pycparser in ./theanoEnv/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->sparseml[torchvision]) (2.21)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in ./theanoEnv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (2.0.7)\n",
            "Requirement already satisfied: rfc3339-validator in ./theanoEnv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./theanoEnv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->sparseml[torchvision]) (0.1.1)\n",
            "Requirement already satisfied: fqdn in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.5.1)\n",
            "Requirement already satisfied: isoduration in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (2.3)\n",
            "Requirement already satisfied: uri-template in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.2.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in ./theanoEnv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.13)\n",
            "Requirement already satisfied: arrow>=0.15.0 in ./theanoEnv/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->sparseml[torchvision]) (1.2.3)\n",
            "Installing collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "Successfully installed setuptools-59.5.0\n",
            "Package                  Version\n",
            "------------------------ --------------------\n",
            "absl-py                  1.4.0\n",
            "anyio                    3.7.0\n",
            "argon2-cffi              21.3.0\n",
            "argon2-cffi-bindings     21.2.0\n",
            "arrow                    1.2.3\n",
            "asttokens                2.2.1\n",
            "attrs                    23.1.0\n",
            "backcall                 0.2.0\n",
            "beautifulsoup4           4.12.2\n",
            "bleach                   6.0.0\n",
            "cachetools               5.3.1\n",
            "certifi                  2023.5.7\n",
            "cffi                     1.15.1\n",
            "charset-normalizer       3.1.0\n",
            "click                    8.0.4\n",
            "comm                     0.1.3\n",
            "contourpy                1.0.7\n",
            "cycler                   0.11.0\n",
            "debugpy                  1.6.7\n",
            "decorator                5.1.1\n",
            "defusedxml               0.7.1\n",
            "exceptiongroup           1.1.1\n",
            "executing                1.2.0\n",
            "fastjsonschema           2.17.1\n",
            "fonttools                4.39.4\n",
            "fqdn                     1.5.1\n",
            "google-auth              2.19.0\n",
            "google-auth-oauthlib     1.0.0\n",
            "GPUtil                   1.4.0\n",
            "gputils                  1.0.6\n",
            "grpcio                   1.54.2\n",
            "idna                     3.4\n",
            "imageio                  2.29.0\n",
            "ipykernel                6.23.1\n",
            "ipython                  8.12.0\n",
            "ipython-genutils         0.2.0\n",
            "ipywidgets               8.0.6\n",
            "isoduration              20.11.0\n",
            "jedi                     0.18.2\n",
            "Jinja2                   3.1.2\n",
            "joblib                   1.2.0\n",
            "jsonpointer              2.3\n",
            "jsonschema               4.17.3\n",
            "jupyter                  1.0.0\n",
            "jupyter_client           8.2.0\n",
            "jupyter-console          6.6.3\n",
            "jupyter_core             5.3.0\n",
            "jupyter-events           0.6.3\n",
            "jupyter_server           2.6.0\n",
            "jupyter_server_terminals 0.4.4\n",
            "jupyterlab-pygments      0.2.2\n",
            "jupyterlab-widgets       3.0.7\n",
            "kiwisolver               1.4.4\n",
            "lazy_loader              0.2\n",
            "Markdown                 3.4.3\n",
            "MarkupSafe               2.1.2\n",
            "matplotlib               3.7.1\n",
            "matplotlib-inline        0.1.6\n",
            "merge-args               0.1.5\n",
            "mistune                  2.0.5\n",
            "nbclassic                1.0.0\n",
            "nbclient                 0.8.0\n",
            "nbconvert                7.4.0\n",
            "nbformat                 5.8.0\n",
            "nest-asyncio             1.5.6\n",
            "networkx                 3.1\n",
            "notebook                 6.5.4\n",
            "notebook_shim            0.2.3\n",
            "numpy                    1.21.6\n",
            "oauthlib                 3.2.2\n",
            "onnx                     1.12.0\n",
            "opencv-python            4.6.0.66\n",
            "overrides                7.3.1\n",
            "packaging                23.1\n",
            "pandas                   2.0.1\n",
            "pandocfilters            1.5.0\n",
            "parso                    0.8.3\n",
            "pexpect                  4.8.0\n",
            "pickleshare              0.7.5\n",
            "Pillow                   9.5.0\n",
            "pip                      23.1.2\n",
            "platformdirs             3.5.1\n",
            "progressbar2             4.2.0\n",
            "prometheus-client        0.17.0\n",
            "prompt-toolkit           3.0.38\n",
            "protobuf                 3.20.1\n",
            "psutil                   5.9.5\n",
            "ptyprocess               0.7.0\n",
            "pure-eval                0.2.2\n",
            "pyasn1                   0.5.0\n",
            "pyasn1-modules           0.3.0\n",
            "pycparser                2.21\n",
            "pydantic                 1.10.8\n",
            "Pygments                 2.15.1\n",
            "pyparsing                3.0.9\n",
            "pyrsistent               0.19.3\n",
            "python-dateutil          2.8.2\n",
            "python-json-logger       2.0.7\n",
            "python-utils             3.5.2\n",
            "pytz                     2023.3\n",
            "PyWavelets               1.4.1\n",
            "PyYAML                   6.0\n",
            "pyzmq                    25.1.0\n",
            "qtconsole                5.4.3\n",
            "QtPy                     2.3.1\n",
            "requests                 2.31.0\n",
            "requests-oauthlib        1.3.1\n",
            "rfc3339-validator        0.1.4\n",
            "rfc3986-validator        0.1.1\n",
            "rsa                      4.9\n",
            "scikit-image             0.20.0\n",
            "scikit-learn             1.2.2\n",
            "scipy                    1.10.1\n",
            "seaborn                  0.12.2\n",
            "Send2Trash               1.8.2\n",
            "setuptools               59.5.0\n",
            "six                      1.16.0\n",
            "sniffio                  1.3.0\n",
            "soupsieve                2.4.1\n",
            "sparseml                 1.4.4\n",
            "sparsezoo                1.4.0\n",
            "stack-data               0.6.2\n",
            "tensorboard              2.13.0\n",
            "tensorboard-data-server  0.7.0\n",
            "terminado                0.17.1\n",
            "Theano                   1.0.5\n",
            "thop                     0.1.1.post2209072238\n",
            "threadpoolctl            3.1.0\n",
            "tifffile                 2023.4.12\n",
            "tinycss2                 1.2.1\n",
            "toposort                 1.10\n",
            "torch                    1.12.0\n",
            "torchvision              0.13.0\n",
            "tornado                  6.3.2\n",
            "tqdm                     4.65.0\n",
            "traitlets                5.9.0\n",
            "typing_extensions        4.6.2\n",
            "tzdata                   2023.3\n",
            "uri-template             1.2.0\n",
            "urllib3                  1.26.16\n",
            "wcwidth                  0.2.6\n",
            "webcolors                1.13\n",
            "webencodings             0.5.1\n",
            "websocket-client         1.5.2\n",
            "Werkzeug                 2.3.4\n",
            "wheel                    0.40.0\n",
            "widgetsnbextension       4.0.7\n",
            "yolov5                   6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EOid6R6R8Jua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Creamos los directorios necesarios\n",
        "os.makedirs('/content/data/train/images', exist_ok=True)\n",
        "os.makedirs('/content/data/train/labels', exist_ok=True)\n",
        "os.makedirs('/content/data/val/images', exist_ok=True)\n",
        "os.makedirs('/content/data/val/labels', exist_ok=True)\n",
        "os.makedirs('/content/data/test/images', exist_ok=True)\n",
        "os.makedirs('/content/data/test/labels', exist_ok=True)\n",
        "\n",
        "dest_train_Image = \"/content/data/train/images/\"\n",
        "dest_train_Label = \"/content/data/train/labels/\"\n",
        "dest_val_Image = \"/content/data/val/images/\"\n",
        "dest_val_Label = \"/content/data/val/labels/\"\n",
        "dest_test_Image = \"/content/data/test/images/\"\n",
        "dest_test_Label = \"/content/data/test/labels/\"\n",
        "\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/train/images') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_train_Image)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/train/labels') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_train_Label)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/val/images') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_val_Image)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/val/labels') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_val_Label)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/test/images') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_test_Image)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/Final_corregido/test/labels') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_test_Label)"
      ],
      "metadata": {
        "id": "vxLPoXWB8ODn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= open(\"Final_corregido.yaml\",\"w+\")\n",
        "\n",
        "f.write(\"path: data \\ntrain: train/images/ \\nval: val/images \\ntest: test/images \\n\\nnc: 4 \\n\\nnames: ['Obligacion', 'Peligro', 'Prohibicion', 'STOP']\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "2Dn0XMl_8Q3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= open(\"yolov5/data/Final_corregido.yaml\",\"w+\")\n",
        "\n",
        "f.write(\"path: ../data \\ntrain: train/images/ \\nval: val/images \\ntest: test/images \\n\\nnc: 4 \\n\\nnames: ['Obligacion', 'Peligro', 'Prohibicion', 'STOP']\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "jNghj5Q0u5V2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/neuralmagic/yolov5"
      ],
      "metadata": {
        "id": "yFpBhO9e8yVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0257b8-c38e-49dc-bc30-50ca81bfcc8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse Transfer Learning Other YOLOv5 Models"
      ],
      "metadata": {
        "id": "1NUVP-74DWwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**YOLOv5s Pruned-Quantized**"
      ],
      "metadata": {
        "id": "Rs_Mu8euG2I_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdPVK0X2zPUs"
      },
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.train \\\n",
        "  --cfg yolov5/models_v5.0/yolov5s.yaml \\\n",
        "  --recipe zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none?recipe_type=transfer_learn \\\n",
        "  --data Final_corregido.yaml \\\n",
        "  --hyp yolov5/data/hyps/hyp.finetune.yaml \\\n",
        "  --weights zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none?recipe_type=transfer_learn \\\n",
        "  --img 640 --batch-size 64 --save-period 15 --optimizer SGD \\\n",
        "  --project \"/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido\" --name \"Small_transfer_learn\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**YOLOv5n Pruned-Quantized**"
      ],
      "metadata": {
        "id": "cp1ZuUyiDabH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.train \\\n",
        "  --cfg yolov5/models_v5.0/yolov5n.yaml \\\n",
        "  --recipe zoo:cv/detection/yolov5-n/pytorch/ultralytics/coco/pruned40_quant-none?recipe_type=transfer_learn \\\n",
        "  --data Final_corregido.yaml \\\n",
        "  --hyp yolov5/data/hyps/hyp.finetune.yaml \\\n",
        "  --weights zoo:cv/detection/yolov5-n/pytorch/ultralytics/coco/pruned40_quant-none?recipe_type=transfer_learn \\\n",
        "  --img 640 --batch-size 64 --save-period 15 --optimizer SGD \\\n",
        "  --project \"/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido\" --name \"Nano_transfer_learn\""
      ],
      "metadata": {
        "id": "4dCbI9USDaAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos las validaciones\n"
      ],
      "metadata": {
        "id": "MuzXL__bQeof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.val \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights/best.pt \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Small_transfer_learn"
      ],
      "metadata": {
        "id": "xc53XjHOQh9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.val \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights/best.pt \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Nano_transfer_learn"
      ],
      "metadata": {
        "id": "GER6R4wWRAnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparsifying YOLOv5 From Scratch"
      ],
      "metadata": {
        "id": "PB4FobKWI8EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**YOLOv5s: 75% Pruned-Quantized**"
      ],
      "metadata": {
        "id": "e55Vw-BnI8x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.train \\\n",
        "  --cfg yolov5/models_v5.0/yolov5s.yaml \\\n",
        "  --teacher-weights zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/base-none \\\n",
        "  --data Final_corregido.yaml \\\n",
        "  --recipe zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned75_quant-none \\\n",
        "  --hyp yolov5/data/hyps/hyp.scratch-low.yaml \\\n",
        "  --weights zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/base-none \\\n",
        "  --patience 0 \\\n",
        "  --gradient-accum-steps 4 \\\n",
        "  --project \"/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido\" --name \"Small_pruned_quant_scratch\""
      ],
      "metadata": {
        "id": "qPnxnAwNI9EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dnth/yolov5-deepsparse-blogpost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufoKb2viMkxH",
        "outputId": "e8747f65-47c6-436a-d328-f1b5aacc721e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5-deepsparse-blogpost'...\n",
            "remote: Enumerating objects: 10412, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/236)\u001b[K\rremote: Counting objects:   1% (3/236)\u001b[K\rremote: Counting objects:   2% (5/236)\u001b[K\rremote: Counting objects:   3% (8/236)\u001b[K\rremote: Counting objects:   4% (10/236)\u001b[K\rremote: Counting objects:   5% (12/236)\u001b[K\rremote: Counting objects:   6% (15/236)\u001b[K\rremote: Counting objects:   7% (17/236)\u001b[K\rremote: Counting objects:   8% (19/236)\u001b[K\rremote: Counting objects:   9% (22/236)\u001b[K\rremote: Counting objects:  10% (24/236)\u001b[K\rremote: Counting objects:  11% (26/236)\u001b[K\rremote: Counting objects:  12% (29/236)\u001b[K\rremote: Counting objects:  13% (31/236)\u001b[K\rremote: Counting objects:  14% (34/236)\u001b[K\rremote: Counting objects:  15% (36/236)\u001b[K\rremote: Counting objects:  16% (38/236)\u001b[K\rremote: Counting objects:  17% (41/236)\u001b[K\rremote: Counting objects:  18% (43/236)\u001b[K\rremote: Counting objects:  19% (45/236)\u001b[K\rremote: Counting objects:  20% (48/236)\u001b[K\rremote: Counting objects:  21% (50/236)\u001b[K\rremote: Counting objects:  22% (52/236)\u001b[K\rremote: Counting objects:  23% (55/236)\u001b[K\rremote: Counting objects:  24% (57/236)\u001b[K\rremote: Counting objects:  25% (59/236)\u001b[K\rremote: Counting objects:  26% (62/236)\u001b[K\rremote: Counting objects:  27% (64/236)\u001b[K\rremote: Counting objects:  28% (67/236)\u001b[K\rremote: Counting objects:  29% (69/236)\u001b[K\rremote: Counting objects:  30% (71/236)\u001b[K\rremote: Counting objects:  31% (74/236)\u001b[K\rremote: Counting objects:  32% (76/236)\u001b[K\rremote: Counting objects:  33% (78/236)\u001b[K\rremote: Counting objects:  34% (81/236)\u001b[K\rremote: Counting objects:  35% (83/236)\u001b[K\rremote: Counting objects:  36% (85/236)\u001b[K\rremote: Counting objects:  37% (88/236)\u001b[K\rremote: Counting objects:  38% (90/236)\u001b[K\rremote: Counting objects:  39% (93/236)\u001b[K\rremote: Counting objects:  40% (95/236)\u001b[K\rremote: Counting objects:  41% (97/236)\u001b[K\rremote: Counting objects:  42% (100/236)\u001b[K\rremote: Counting objects:  43% (102/236)\u001b[K\rremote: Counting objects:  44% (104/236)\u001b[K\rremote: Counting objects:  45% (107/236)\u001b[K\rremote: Counting objects:  46% (109/236)\u001b[K\rremote: Counting objects:  47% (111/236)\u001b[K\rremote: Counting objects:  48% (114/236)\u001b[K\rremote: Counting objects:  49% (116/236)\u001b[K\rremote: Counting objects:  50% (118/236)\u001b[K\rremote: Counting objects:  51% (121/236)\u001b[K\rremote: Counting objects:  52% (123/236)\u001b[K\rremote: Counting objects:  53% (126/236)\u001b[K\rremote: Counting objects:  54% (128/236)\u001b[K\rremote: Counting objects:  55% (130/236)\u001b[K\rremote: Counting objects:  56% (133/236)\u001b[K\rremote: Counting objects:  57% (135/236)\u001b[K\rremote: Counting objects:  58% (137/236)\u001b[K\rremote: Counting objects:  59% (140/236)\u001b[K\rremote: Counting objects:  60% (142/236)\u001b[K\rremote: Counting objects:  61% (144/236)\u001b[K\rremote: Counting objects:  62% (147/236)\u001b[K\rremote: Counting objects:  63% (149/236)\u001b[K\rremote: Counting objects:  64% (152/236)\u001b[K\rremote: Counting objects:  65% (154/236)\u001b[K\rremote: Counting objects:  66% (156/236)\u001b[K\rremote: Counting objects:  67% (159/236)\u001b[K\rremote: Counting objects:  68% (161/236)\u001b[K\rremote: Counting objects:  69% (163/236)\u001b[K\rremote: Counting objects:  70% (166/236)\u001b[K\rremote: Counting objects:  71% (168/236)\u001b[K\rremote: Counting objects:  72% (170/236)\u001b[K\rremote: Counting objects:  73% (173/236)\u001b[K\rremote: Counting objects:  74% (175/236)\u001b[K\rremote: Counting objects:  75% (177/236)\u001b[K\rremote: Counting objects:  76% (180/236)\u001b[K\rremote: Counting objects:  77% (182/236)\u001b[K\rremote: Counting objects:  78% (185/236)\u001b[K\rremote: Counting objects:  79% (187/236)\u001b[K\rremote: Counting objects:  80% (189/236)\u001b[K\rremote: Counting objects:  81% (192/236)\u001b[K\rremote: Counting objects:  82% (194/236)\u001b[K\rremote: Counting objects:  83% (196/236)\u001b[K\rremote: Counting objects:  84% (199/236)\u001b[K\rremote: Counting objects:  85% (201/236)\u001b[K\rremote: Counting objects:  86% (203/236)\u001b[K\rremote: Counting objects:  87% (206/236)\u001b[K\rremote: Counting objects:  88% (208/236)\u001b[K\rremote: Counting objects:  89% (211/236)\u001b[K\rremote: Counting objects:  90% (213/236)\u001b[K\rremote: Counting objects:  91% (215/236)\u001b[K\rremote: Counting objects:  92% (218/236)\u001b[K\rremote: Counting objects:  93% (220/236)\u001b[K\rremote: Counting objects:  94% (222/236)\u001b[K\rremote: Counting objects:  95% (225/236)\u001b[K\rremote: Counting objects:  96% (227/236)\u001b[K\rremote: Counting objects:  97% (229/236)\u001b[K\rremote: Counting objects:  98% (232/236)\u001b[K\rremote: Counting objects:  99% (234/236)\u001b[K\rremote: Counting objects: 100% (236/236)\u001b[K\rremote: Counting objects: 100% (236/236), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 10412 (delta 97), reused 227 (delta 93), pack-reused 10176\u001b[K\n",
            "Receiving objects: 100% (10412/10412), 1.10 GiB | 30.81 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n",
            "Updating files: 100% (9702/9702), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Small Blog"
      ],
      "metadata": {
        "id": "e3mHjUcHNcju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.train \\\n",
        "                --recipe /content/yolov5-deepsparse-blogpost/recipes/yolov5.transfer_learn_pruned_quantized.md \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --hyp yolov5/data/hyps/hyp.scratch-low.yaml \\\n",
        "                --weights yolov5s.pt --img 640 \\\n",
        "                --batch-size 64 --optimizer SGD \\\n",
        "                --project \"/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido\" --name \"Small_pruned_quant_Blog\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTHNuO4VMcAR",
        "outputId": "70a397e8-dcdd-4584-c127-dbe2d14f276a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, teacher_weights=, data=Final_corregido.yaml, data_path=, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=64, gradient_accum_steps=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido, name=Small_pruned_quant_Blog, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, recipe=/content/yolov5-deepsparse-blogpost/recipes/yolov5.transfer_learn_pruned_quantized.md, recipe_args=None, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2023-5-28 Python-3.10.11 torch-1.12.0+cu102 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 210MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  yolov5.models.yolo.Detect               [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/train/labels.cache' images and labels... 984 found, 0 missing, 180 empty, 0 corrupt: 100% 984/984 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/val/labels.cache' images and labels... 70 found, 0 missing, 8 empty, 0 corrupt: 100% 70/70 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.92 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/labels.jpg... \n",
            "2023-05-28 11:52:47 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_11.52.47.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_11.52.47.log\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mSparse training detected. Wrapping training process with SparseML\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mDisabling LR scheduler, managing LR using SparseML recipe\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOverriding total number of training epochs with value from recipe: 240\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog\u001b[0m\n",
            "Starting training for 240 epochs...\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/239      12.4G     0.1181    0.03938    0.04592         91        640: 100% 16/16 [00:34<00:00,  2.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.89s/it]\n",
            "                   all         70        263    0.00248      0.193    0.00666    0.00161\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/239      13.4G    0.08724    0.04327    0.04054        118        640: 100% 16/16 [00:29<00:00,  1.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.59s/it]\n",
            "                   all         70        263      0.115      0.383      0.156     0.0498\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      2/239      13.4G    0.06648     0.0361    0.03711         83        640: 100% 16/16 [00:34<00:00,  2.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.75s/it]\n",
            "                   all         70        263      0.198      0.433      0.232     0.0759\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      3/239      13.4G    0.05925    0.02883    0.03369        120        640: 100% 16/16 [00:32<00:00,  2.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.47s/it]\n",
            "                   all         70        263      0.397      0.529      0.468      0.224\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      4/239      13.4G    0.05425    0.02678    0.03002        151        640: 100% 16/16 [00:34<00:00,  2.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.25s/it]\n",
            "                   all         70        263      0.401      0.556      0.508        0.2\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      5/239      13.5G    0.05042    0.02434    0.02633        100        640: 100% 16/16 [00:31<00:00,  1.99s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.01s/it]\n",
            "                   all         70        263       0.41      0.617      0.516      0.211\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      6/239      13.5G    0.04818    0.02316    0.02337        139        640: 100% 16/16 [00:34<00:00,  2.14s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.89s/it]\n",
            "                   all         70        263      0.467      0.682      0.601      0.308\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      7/239      13.5G    0.04542      0.021    0.02131        111        640: 100% 16/16 [00:32<00:00,  2.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                   all         70        263       0.51      0.704      0.638      0.334\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      8/239      13.5G    0.04305    0.02069    0.01978        118        640: 100% 16/16 [00:34<00:00,  2.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.67s/it]\n",
            "                   all         70        263      0.694      0.708      0.748      0.411\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      9/239      13.5G    0.04154    0.01882    0.01804         98        640: 100% 16/16 [00:31<00:00,  1.95s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.23s/it]\n",
            "                   all         70        263      0.784      0.742      0.806      0.463\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     10/239      13.5G    0.04012    0.01927    0.01667        108        640: 100% 16/16 [00:34<00:00,  2.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.72s/it]\n",
            "                   all         70        263      0.662      0.731      0.741      0.395\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     11/239      13.5G    0.03932    0.01889    0.01453         96        640: 100% 16/16 [00:31<00:00,  1.97s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.32s/it]\n",
            "                   all         70        263      0.776      0.756      0.829      0.472\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     12/239      13.5G    0.03912    0.01805     0.0118         97        640: 100% 16/16 [00:32<00:00,  2.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.84s/it]\n",
            "                   all         70        263      0.767      0.817      0.858      0.447\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     13/239      13.5G    0.03768     0.0176   0.009198        119        640: 100% 16/16 [00:33<00:00,  2.09s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all         70        263      0.783      0.842      0.875      0.511\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     14/239      13.5G    0.03707    0.01767   0.007988        108        640: 100% 16/16 [00:30<00:00,  1.92s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.94s/it]\n",
            "                   all         70        263      0.826      0.844      0.896      0.519\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     15/239      13.5G    0.03681    0.01725   0.007642        137        640: 100% 16/16 [00:34<00:00,  2.18s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.28s/it]\n",
            "                   all         70        263      0.849      0.862      0.906      0.581\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     16/239      13.5G    0.03634    0.01758   0.006782        142        640: 100% 16/16 [00:30<00:00,  1.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.02s/it]\n",
            "                   all         70        263      0.865      0.892      0.933      0.599\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     17/239      13.5G    0.03569    0.01735   0.006588         80        640: 100% 16/16 [00:34<00:00,  2.13s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.88s/it]\n",
            "                   all         70        263      0.912      0.823      0.928      0.596\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     18/239      13.5G     0.0345    0.01772   0.006226        128        640: 100% 16/16 [00:30<00:00,  1.92s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all         70        263      0.892      0.865      0.926      0.606\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     19/239      13.5G    0.03404    0.01676   0.005905        129        640: 100% 16/16 [00:33<00:00,  2.09s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.04s/it]\n",
            "                   all         70        263      0.894      0.909      0.936      0.631\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     20/239      13.5G     0.0335    0.01711   0.005845        136        640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.24s/it]\n",
            "                   all         70        263      0.866      0.891       0.93      0.628\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     21/239      13.5G    0.03329    0.01625   0.005761        117        640: 100% 16/16 [00:32<00:00,  2.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.83s/it]\n",
            "                   all         70        263      0.898      0.871      0.936      0.643\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     22/239      13.5G     0.0324    0.01648   0.005334        119        640: 100% 16/16 [00:34<00:00,  2.13s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
            "                   all         70        263      0.893      0.899      0.941       0.61\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     23/239      13.5G    0.03198    0.01619   0.004856        111        640: 100% 16/16 [00:31<00:00,  1.97s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.04s/it]\n",
            "                   all         70        263       0.89       0.89      0.938      0.635\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     24/239      13.5G    0.03161    0.01568   0.005076         87        640: 100% 16/16 [00:34<00:00,  2.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.50s/it]\n",
            "                   all         70        263      0.885      0.891      0.943      0.658\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     25/239      13.5G    0.03134    0.01587   0.005095        119        640: 100% 16/16 [00:32<00:00,  2.04s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.17s/it]\n",
            "                   all         70        263      0.852      0.904      0.943      0.665\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     26/239      13.5G    0.03106    0.01567    0.00452        107        640: 100% 16/16 [00:35<00:00,  2.20s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all         70        263      0.892      0.864       0.94       0.67\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     27/239      13.5G    0.03071    0.01563   0.004626         92        640: 100% 16/16 [00:30<00:00,  1.93s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:02<00:00,  2.02s/it]\n",
            "                   all         70        263      0.911      0.879      0.949      0.632\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     28/239      13.5G    0.03094     0.0157   0.004496        120        640: 100% 16/16 [00:35<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all         70        263      0.899      0.893      0.948       0.65\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     29/239      13.5G    0.02996    0.01565   0.004462        124        640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.49s/it]\n",
            "                   all         70        263      0.919      0.883      0.952      0.669\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     30/239      13.5G    0.03033    0.01463   0.004526        275        640:  88% 14/16 [00:30<00:04,  2.16s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nano blog"
      ],
      "metadata": {
        "id": "FKkQ6SIrNZOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.train \\\n",
        "                --cfg /content/yolov5-deepsparse-blogpost/yolov5-train/models_v5.0/yolov5n.yaml \\\n",
        "                --recipe /content/yolov5-deepsparse-blogpost/recipes/yolov5.transfer_learn_pruned_quantized.md \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --hyp yolov5/data/hyps/hyp.scratch-low.yaml \\\n",
        "                --weights yolov5n.pt --img 640 \\\n",
        "                --batch-size 64 --optimizer SGD --device 0 \\\n",
        "                --project \"/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido\" --name \"Nano_pruned_quant_Blog\""
      ],
      "metadata": {
        "id": "DMXPaXytNY1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validaciones sparseml"
      ],
      "metadata": {
        "id": "5ZfNPblUuZt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.val \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Small_pruned_quant_Blog"
      ],
      "metadata": {
        "id": "SAxn7hlsRKH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.val \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Nano_pruned_quant_Blog"
      ],
      "metadata": {
        "id": "l-jD_7hURK7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validaciones Yolov5"
      ],
      "metadata": {
        "id": "r_g3V25fucmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Small_pruned_quant_Blog"
      ],
      "metadata": {
        "id": "n7n0A_XwuY8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "#                 --task test \\\n",
        "#                 --data Final_corregido.yaml \\\n",
        "#                 --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "#                 --conf-thres 0.40 \\\n",
        "#                 --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Nano_pruned_quant_Blog"
      ],
      "metadata": {
        "id": "R2iK_TcCuhH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exportamos los modelos a formato onnx"
      ],
      "metadata": {
        "id": "33rlgbCPveU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.export_onnx \\\n",
        "  --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights/best_pruned.pt \\\n",
        "  --dynamic"
      ],
      "metadata": {
        "id": "j9VENTsIvjUW",
        "outputId": "0d4ccd95-22f7-415f-dcd6-c760469197ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "YOLOv5 🚀 2023-5-28 Python-3.10.11 torch-1.12.0+cu102 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mLoading sparsified model\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Focus              [3, 32, 3]                    \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  yolov5.models.common.C3                 [128, 128, 3]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  yolov5.models.common.SPP                [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  yolov5.models.yolo.Detect               [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 225 layers, 7071633 parameters, 7071633 gradients\n",
            "\n",
            "2023-05-28 14:27:20 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.20.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.20.log\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights/best_pruned.pt with output shape (1, 25200, 9) (13.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExporting model to ONNX format\n",
            "/content/theanoEnv/lib/python3.10/site-packages/torch/onnx/utils.py:439: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
            "  warnings.warn(\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExported ONNX model to drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 8.4s, saved as drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx (27.1 MB)\n",
            "\n",
            "Export complete (9.9s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/weights\u001b[0m\n",
            "Detect:          python detect.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \n",
            "Validate:        python val.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.export_onnx \\\n",
        "  --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights/best_pruned.pt \\\n",
        "  --dynamic"
      ],
      "metadata": {
        "id": "aXZqZ3wrwGAY",
        "outputId": "6d915e4a-5750-4d75-be8f-47ba6b7378e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "YOLOv5 🚀 2023-5-28 Python-3.10.11 torch-1.12.0+cu102 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mLoading sparsified model\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  yolov5.models.common.Conv               [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  yolov5.models.common.Conv               [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  yolov5.models.common.C3                 [32, 32, 1]                   \n",
            "  3                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  yolov5.models.common.C3                 [64, 64, 2]                   \n",
            "  5                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  yolov5.models.common.C3                 [128, 128, 3]                 \n",
            "  7                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1]                 \n",
            "  9                -1  1    164608  yolov5.models.common.SPPF               [256, 256, 5]                 \n",
            " 10                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 14                -1  1      8320  yolov5.models.common.Conv               [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     22912  yolov5.models.common.C3                 [128, 64, 1, False]           \n",
            " 18                -1  1     36992  yolov5.models.common.Conv               [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1     74496  yolov5.models.common.C3                 [128, 128, 1, False]          \n",
            " 21                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1     12177  yolov5.models.yolo.Detect               [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1769329 parameters, 1769329 gradients, 4.2 GFLOPs\n",
            "\n",
            "2023-05-28 14:27:43 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.43.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.43.log\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights/best_pruned.pt with output shape (1, 25200, 9) (3.5 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExporting model to ONNX format\n",
            "/content/theanoEnv/lib/python3.10/site-packages/torch/onnx/utils.py:439: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
            "  warnings.warn(\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExported ONNX model to drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.2s, saved as drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx (6.9 MB)\n",
            "\n",
            "Export complete (6.3s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/weights\u001b[0m\n",
            "Detect:          python detect.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \n",
            "Validate:        python val.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; sparseml.yolov5.export_onnx \\\n",
        "  --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "  --dynamic"
      ],
      "metadata": {
        "id": "fzAuQee_wGbf",
        "outputId": "93262e00-7991-41fb-9f6b-b33965a83cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=theanoEnv/lib/python3.10/site-packages/yolov5/data/coco128.yaml, data_path=, weights=['drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=True, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, export_samples=0, include=['onnx'], one_shot=None\n",
            "YOLOv5 🚀 2023-5-28 Python-3.10.11 torch-1.12.0+cu102 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mLoading sparsified model\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
            "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
            "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
            "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
            "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
            " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
            " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  yolov5.models.yolo.Detect               [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n",
            "2023-05-28 14:27:57 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.57.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/28-05-2023_14.27.57.log\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights/best_pruned.pt with output shape (1, 25200, 9) (13.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExporting model to ONNX format\n",
            "/content/theanoEnv/lib/python3.10/site-packages/torch/onnx/utils.py:439: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
            "  warnings.warn(\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mExported ONNX model to drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.9s, saved as drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx (27.0 MB)\n",
            "\n",
            "Export complete (8.8s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/weights\u001b[0m\n",
            "Detect:          python detect.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx \n",
            "Validate:        python val.py --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/theanoEnv/bin/activate; sparseml.yolov5.export_onnx \\\n",
        "#   --weights drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_pruned_quant_Blog/weights/best_pruned.pt \\\n",
        "#   --dynamic"
      ],
      "metadata": {
        "id": "VnNPnkFSwGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Validamos los modelos en el nuevo formato***"
      ],
      "metadata": {
        "id": "hwJCFtnkwnvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Small_transfer_learn_onnx"
      ],
      "metadata": {
        "id": "11UrMM9Rw_iY",
        "outputId": "6be089ad-c40a-486e-f398-17a1300fbdd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/Final_corregido.yaml, data_path=, weights=['../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx'], batch_size=32, imgsz=640, conf_thres=0.4, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas, name=Small_transfer_learn_onnx, exist_ok=False, half=False, dnn=False, deepsparse=False\n",
            "WARNING ⚠️ confidence threshold 0.4 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 data-95-gadaf4ef Python-3.10.11 torch-1.12.0+cu102 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_transfer_learn/DeepSparse_Deployment/best_pruned.onnx for ONNX Runtime inference...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"onnxruntime-gpu\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (122.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.2/122.2 MB 8.5 MB/s eta 0:00:00\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 4.9 MB/s eta 0:00:00\n",
            "Collecting flatbuffers (from onnxruntime-gpu)\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /content/theanoEnv/lib/python3.10/site-packages (from onnxruntime-gpu) (1.21.6)\n",
            "Requirement already satisfied: packaging in /content/theanoEnv/lib/python3.10/site-packages (from onnxruntime-gpu) (23.1)\n",
            "Requirement already satisfied: protobuf in /content/theanoEnv/lib/python3.10/site-packages (from onnxruntime-gpu) (3.20.1)\n",
            "Collecting sympy (from onnxruntime-gpu)\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 119.6 MB/s eta 0:00:00\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 12.2 MB/s eta 0:00:00\n",
            "Collecting mpmath>=0.19 (from sympy->onnxruntime-gpu)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 46.0 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, flatbuffers, sympy, humanfriendly, coloredlogs, onnxruntime-gpu\n",
            "Successfully installed coloredlogs-15.0.1 flatbuffers-23.5.26 humanfriendly-10.0 mpmath-1.3.0 onnxruntime-gpu-1.15.0 sympy-1.12\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ('onnx', 'onnxruntime-gpu')\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/data/test/labels.cache' images and labels... 50 found, 0 missing, 1 empty, 0 corrupt: 100% 50/50 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 50/50 [00:01<00:00, 43.21it/s]\n",
            "                   all         50        139      0.752      0.265      0.504      0.357\n",
            "                     0         50         17       0.25     0.0588      0.146      0.117\n",
            "                     1         50         64       0.98      0.766      0.879      0.601\n",
            "                     2         50         46      0.778      0.152      0.448      0.332\n",
            "                     3         50         12          1     0.0833      0.542      0.379\n",
            "Speed: 0.5ms pre-process, 11.6ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas/Small_transfer_learn_onnx\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Nano_transfer_learn_onnx"
      ],
      "metadata": {
        "id": "VF5iL4tzw_Oe",
        "outputId": "0f53521c-f1b9-4619-ffa0-eab4ee08e29d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/Final_corregido.yaml, data_path=, weights=['../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx'], batch_size=32, imgsz=640, conf_thres=0.4, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas, name=Nano_transfer_learn_onnx, exist_ok=False, half=False, dnn=False, deepsparse=False\n",
            "WARNING ⚠️ confidence threshold 0.4 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 data-95-gadaf4ef Python-3.10.11 torch-1.12.0+cu102 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_transfer_learn/DeepSparse_Deployment/best_pruned.onnx for ONNX Runtime inference...\n",
            "Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/data/test/labels.cache' images and labels... 50 found, 0 missing, 1 empty, 0 corrupt: 100% 50/50 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 50/50 [00:01<00:00, 48.96it/s]\n",
            "                   all         50        139      0.682      0.205      0.445      0.338\n",
            "                     0         50         17          0          0          0          0\n",
            "                     1         50         64      0.977      0.672      0.832      0.525\n",
            "                     2         50         46       0.75     0.0652      0.406      0.339\n",
            "                     3         50         12          1     0.0833      0.542      0.487\n",
            "Speed: 0.4ms pre-process, 8.7ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas/Nano_transfer_learn_onnx\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "                --task test \\\n",
        "                --data Final_corregido.yaml \\\n",
        "                --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx \\\n",
        "                --conf-thres 0.40 \\\n",
        "                --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Small_pruned_quant_Blog_onnx"
      ],
      "metadata": {
        "id": "ctf0cdAjwstu",
        "outputId": "ca9aab1f-bdb9-4395-8df4-8a8646eb8c04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/Final_corregido.yaml, data_path=, weights=['../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx'], batch_size=32, imgsz=640, conf_thres=0.4, iou_thres=0.6, max_det=300, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas, name=Small_pruned_quant_Blog_onnx, exist_ok=False, half=False, dnn=False, deepsparse=False\n",
            "WARNING ⚠️ confidence threshold 0.4 > 0.001 produces invalid results\n",
            "YOLOv5 🚀 data-95-gadaf4ef Python-3.10.11 torch-1.12.0+cu102 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Loading ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Small_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx for ONNX Runtime inference...\n",
            "Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/data/test/labels.cache' images and labels... 50 found, 0 missing, 1 empty, 0 corrupt: 100% 50/50 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 50/50 [00:01<00:00, 28.62it/s]\n",
            "                   all         50        139       0.92      0.885       0.94        0.7\n",
            "                     0         50         17      0.866      0.882      0.938      0.675\n",
            "                     1         50         64      0.923      0.766      0.885      0.632\n",
            "                     2         50         46       0.89      0.891      0.943      0.706\n",
            "                     3         50         12          1          1      0.995      0.785\n",
            "Speed: 0.6ms pre-process, 13.2ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas/Small_pruned_quant_Blog_onnx\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !source /content/theanoEnv/bin/activate; cd yolov5 && python val.py \\\n",
        "#                 --task test \\\n",
        "#                 --data Final_corregido.yaml \\\n",
        "#                 --weights ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Nano_pruned_quant_Blog/DeepSparse_Deployment/best_pruned.onnx \\\n",
        "#                 --conf-thres 0.40 \\\n",
        "#                 --project ../drive/MyDrive/IA/Pesos_yoloV5/Final_corregido/Metricas --name Nano_pruned_quant_Blog_onnx"
      ],
      "metadata": {
        "id": "yM7RA8pjxAif"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}