{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markkolas/TP2/blob/jorge-test/OneClass/OneClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n_Ko1xe5vmSb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "BdaVGv8rvrD8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install torch torchvision torchaudio "
      ],
      "metadata": {
        "id": "1v0wh0Kzvs96"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "RKvthXUevu46"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/yolov5\n",
        "!git pull\n",
        "%cd ../"
      ],
      "metadata": {
        "id": "cmzb83PUv-ky"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "HQPzl6QzwAAa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 #Para abrir webcam\n",
        "# cv2.imshow() is disabled in Colab, because it causes Jupyter sessionsto crash, consider using cv2_imshow \n",
        "from google.colab.patches import cv2_imshow \n",
        "import sys # to access the system\n",
        "\n",
        "# Esta lÃ­nea de cÃ³digo establece una variable de entorno llamada KMP_DUPLICATE_LIB_OK con el valor \"True\", lo que significa que permite la carga de bibliotecas duplicadas en el entorno de Python. Esto es Ãºtil para algunas bibliotecas de Machine Learning que usan OpenMP para acelerar el cÃ³mputo.\n",
        "import os    \n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
      ],
      "metadata": {
        "id": "uovDTFbCwBlL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Creamos los directorios necesarios\n",
        "os.makedirs('/content/data/train/images', exist_ok=True)\n",
        "os.makedirs('/content/data/train/labels', exist_ok=True)\n",
        "os.makedirs('/content/data/val/images', exist_ok=True)\n",
        "os.makedirs('/content/data/val/labels', exist_ok=True)\n",
        "\n",
        "dest_train_Image = \"/content/data/train/images/\"\n",
        "dest_train_Label = \"/content/data/train/labels/\"\n",
        "dest_val_Image = \"/content/data/val/images/\"\n",
        "dest_val_Label = \"/content/data/val/labels/\"\n",
        "\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/One Class/train/images') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_train_Image)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/One Class/train/labels') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_train_Label)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/One Class/val/images') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_val_Image)\n",
        "\n",
        "with os.scandir('/content/drive/MyDrive/IA/Datasets/One Class/val/labels') as entries:\n",
        "  for entry in entries:\n",
        "    shutil.copy2(entry.path, dest_val_Label)"
      ],
      "metadata": {
        "id": "odDjyoF6wEAz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f= open(\"yolov5/data/OneClass.yaml\",\"w+\")\n",
        "\n",
        "f.write(\"path: ../data \\ntrain: train/images/ \\nval: val/images \\ntest: test/images \\n\\nnc: 1 \\n\\nnames: ['SeÃ±al']\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "PRatlsX1wg2D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy2(\"/content/yolov5/requirements.txt\", \"/content/requirements.txt\")\n",
        "!cd yolov5 && python train.py --img 640 --batch -1 --epochs 100 --data OneClass.yaml --weights yolov5s.pt --project ../drive/MyDrive/IA/Pesos_yoloV5/OneClass --save-period 10"
      ],
      "metadata": {
        "id": "OhLeJU-OxGtV",
        "outputId": "74e30da1-b15f-42ce-c0df-91bc1d09e97d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=OneClass.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=-1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../drive/MyDrive/IA/Pesos_yoloV5/OneClass, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=150, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-163-g016e046 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../drive/MyDrive/IA/Pesos_yoloV5/OneClass', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.Unicode.ttf to /root/.config/Ultralytics/Arial.Unicode.ttf...\n",
            "100% 22.2M/22.2M [00:00<00:00, 31.8MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:01<00:00, 10.6MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd yolov5 && python train.py --resume ../drive/MyDrive/IA/Pesos_yoloV5/OneClass/exp/weights/last.pt"
      ],
      "metadata": {
        "id": "DJBbQM_B3PW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}