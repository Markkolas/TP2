{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlzVScSJyc_0"
      },
      "source": [
        "# Re_entreno"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Añadimos acceso a la carpeta de los dataset del Drive del grupo de proyectos\n",
        "\n",
        "Importante estar ya logeados en la cuenta del grupo, da problemas si estamos en nuestra cuenta personal y queremos montar el drive de la cuenta del grupo."
      ],
      "metadata": {
        "id": "EhN3HZ6kzATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wtN50Mf6zYMH",
        "outputId": "32944b46-8e06-43b7-fcfe-87648b54c3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos las bibliotecas necesarias"
      ],
      "metadata": {
        "id": "NC17ND1bzRQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kEn22pyqyc_1",
        "outputId": "6691f7e4-4bc7-40fb-9dfc-a36b6b4e05e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PeYrZcbhyc_2",
        "outputId": "33b82869-44aa-4c46-e9a3-3f431edbf3a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Para windows con la CPU:\n",
        "!pip3 install torch torchvision torchaudio \n",
        "\n",
        "# Para Windows con CUDA:\n",
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "# Para windows con la CPU:\n",
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "# Para Windows con CUDA:\n",
        "# !pip3 install torch torchvision torchaudio\n",
        "\n",
        "# Es posible que la mayoría de dependencias ya esten instaladas ^^"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vhpO93V5yc_2",
        "outputId": "9f7a1ec1-d5a7-419a-d578-d101b34b79ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15532, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 15532 (delta 51), reused 118 (delta 43), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15532/15532), 14.59 MiB | 22.33 MiB/s, done.\n",
            "Resolving deltas: 100% (10575/10575), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "# Se deberia haber creado una carpeta en nuestro area de trabajo\n",
        "# Si ya lo teniamos saldra el siguiente error =>fatal: destination path 'yolov5' already exists and is not an empty directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "55dyjau8yc_2",
        "outputId": "564ba1b7-65ea-4f0f-d3b8-a2ca4529c5b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd yolov5 & pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0GVUlxwZyc_3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 #Para abrir webcam\n",
        "# cv2.imshow() is disabled in Colab, because it causes Jupyter sessionsto crash, consider using cv2_imshow \n",
        "from google.colab.patches import cv2_imshow \n",
        "import sys # to access the system\n",
        "\n",
        "# Esta línea de código establece una variable de entorno llamada KMP_DUPLICATE_LIB_OK con el valor \"True\", lo que significa que permite la carga de bibliotecas duplicadas en el entorno de Python. Esto es útil para algunas bibliotecas de Machine Learning que usan OpenMP para acelerar el cómputo.\n",
        "import os    \n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2jrDuTDyc_3"
      },
      "source": [
        "***\n",
        "En la siguiente celda se escogen 100 imagenes para hacer el re-entreno.\n",
        " \n",
        "Además esas imagenes se suben a unas carpetas que creamos en el directorio base de colabs.\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/IA/Datasets/YoloV5/00001.jpg', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "fBPtsfk62jri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VMh78Gt1yc_3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Creamos los directorios necesarios\n",
        "os.makedirs('/content/data/images', exist_ok=True)\n",
        "os.makedirs('/content/data/labels', exist_ok=True)\n",
        "\n",
        "random.seed(15)\n",
        "\n",
        "src = \"/content/drive/MyDrive/IA/Datasets/YoloV5/\"\n",
        "dest_Image = \"/content/data/images/\"\n",
        "dest_Label = \"/content/data/labels/\"\n",
        "\n",
        "lista_aleatorios_rellenada = []\n",
        "\n",
        "for n in range(100):\n",
        "  aleatorio = random.randint(0,900)\n",
        "  aleatorio_rellenado = str(aleatorio).zfill(5)\n",
        "  src_img = src + str(aleatorio_rellenado) + \".jpg\"\n",
        "  if os.path.exists(src_img):\n",
        "    if aleatorio_rellenado not in lista_aleatorios_rellenada:\n",
        "      lista_aleatorios_rellenada.append(aleatorio_rellenado)\n",
        "\n",
        "# print(lista_aleatorios_rellenada)\n",
        "\n",
        "for num in lista_aleatorios_rellenada:\n",
        "  src_img = src + str(num) + \".jpg\"\n",
        "  dest_img = dest_Image + str(num) + \".jpg\"\n",
        "  shutil.copy2(src_img, dest_img)\n",
        "  # print(dest_img)\n",
        "\n",
        "for num in lista_aleatorios_rellenada:\n",
        "  src_lab = src + str(num) + \".txt\"\n",
        "  dest_lab = dest_Label + str(num) + \".txt\"\n",
        "  shutil.copy2(src_lab, dest_lab)\n",
        "  # print(dest_lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPbz8qatyc_3"
      },
      "source": [
        "***\n",
        "**`Entrenar un modelo desde cero`**\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ3DLRW9yc_4"
      },
      "source": [
        "Ahora tenemos que crear el archivo dataset.yaml, que contiene las categorias de nuestros pesos y las rutas de nuestras imagenes de entrenamiento, test y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NLliUqibyc_4"
      },
      "outputs": [],
      "source": [
        "f= open(\"yolov5/data/cien_images_señales.yaml\",\"w+\")\n",
        "\n",
        "f.write(\"path: ../data \\ntrain: images \\nval: images \\n\\nnc: 4 \\n\\nnames: ['prohibitory', 'danger', 'mandatory', 'other']\")\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUxnSp18yc_4",
        "outputId": "616910df-ea3b-4189-cefd-1433acac6f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"gitpython\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 5.1 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 8.0 MB/s eta 0:00:00\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['gitpython']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=cien_images_señales.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=500, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), 2.76 KiB | 1.38 MiB/s, done.\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   94714fe..aa7c45c  master     -> origin/master\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 2 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-145-g94714fe Python-3.9.16 torch-2.0.0+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 13.6MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 99.1MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7030417 parameters, 7030417 gradients\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels... 62 images, 0 backgrounds, 0 corrupt: 100% 62/62 [00:00<00:00, 984.94it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels.cache... 62 images, 0 backgrounds, 0 corrupt: 100% 62/62 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.56 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 500 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/499         0G     0.1364    0.02621    0.05013         43        640: 100% 4/4 [02:08<00:00, 32.08s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:11<00:11, 11.81s/it]WARNING ⚠️ NMS time limit 2.000s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:24<00:00, 12.19s/it]\n",
            "                   all         62        104          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      1/499         0G     0.1358    0.02427      0.049         35        640: 100% 4/4 [01:35<00:00, 23.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/2 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:12<00:12, 12.91s/it]WARNING ⚠️ NMS time limit 2.000s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:25<00:00, 12.63s/it]\n",
            "                   all         62        104   0.000184     0.0147   0.000106   2.05e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      2/499         0G     0.1301    0.02464    0.04658         43        640: 100% 4/4 [01:35<00:00, 23.89s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:24<00:00, 12.43s/it]\n",
            "                   all         62        104   0.000136     0.0147    0.00016   5.33e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      3/499         0G     0.1235    0.02189     0.0426         32        640: 100% 4/4 [01:34<00:00, 23.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50% 1/2 [00:12<00:12, 12.36s/it]WARNING ⚠️ NMS time limit 2.000s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:22<00:00, 11.48s/it]\n",
            "                   all         62        104   0.000135     0.0147   0.000538   0.000161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      4/499         0G     0.1235    0.02373    0.04268         51        640: 100% 4/4 [01:34<00:00, 23.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:22<00:00, 11.03s/it]\n",
            "                   all         62        104   0.000235     0.0294     0.0014   0.000347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      5/499         0G     0.1211     0.0223    0.04248         36        640: 100% 4/4 [01:42<00:00, 25.67s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:22<00:00, 11.24s/it]\n",
            "                   all         62        104   0.000165     0.0221   0.000387    8.2e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      6/499         0G     0.1169    0.02199    0.04074         40        640: 100% 4/4 [01:32<00:00, 23.12s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:21<00:00, 10.63s/it]\n",
            "                   all         62        104   0.000463     0.0424   0.000419   7.38e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      7/499         0G     0.1183    0.02148     0.0394         53        640: 100% 4/4 [01:34<00:00, 23.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:22<00:00, 11.08s/it]\n",
            "                   all         62        104   0.000597     0.0555    0.00216   0.000613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      8/499         0G      0.111    0.02258     0.0379         42        640: 100% 4/4 [01:32<00:00, 23.10s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.18s/it]\n",
            "                   all         62        104    0.00173      0.122    0.00487    0.00198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      9/499         0G     0.1059     0.0214    0.03715         30        640: 100% 4/4 [01:31<00:00, 22.92s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.73s/it]\n",
            "                   all         62        104    0.00211      0.223     0.0107    0.00398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     10/499         0G     0.1023    0.02145    0.03616         32        640: 100% 4/4 [01:30<00:00, 22.69s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.26s/it]\n",
            "                   all         62        104    0.00232      0.276     0.0137    0.00346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     11/499         0G    0.09896      0.019    0.03644         31        640: 100% 4/4 [01:30<00:00, 22.60s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.65s/it]\n",
            "                   all         62        104    0.00266      0.368     0.0181    0.00431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     12/499         0G    0.09746    0.02148    0.03582         41        640: 100% 4/4 [01:31<00:00, 22.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.04s/it]\n",
            "                   all         62        104    0.00309      0.463     0.0346    0.00984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     13/499         0G    0.09303    0.02272    0.03426         43        640: 100% 4/4 [01:30<00:00, 22.54s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.77s/it]\n",
            "                   all         62        104    0.00342      0.543     0.0676     0.0169\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     14/499         0G    0.09236    0.02123    0.03544         26        640: 100% 4/4 [01:33<00:00, 23.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.40s/it]\n",
            "                   all         62        104    0.00358      0.552     0.0869     0.0293\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     15/499         0G    0.09304    0.02428    0.03404         48        640: 100% 4/4 [01:31<00:00, 22.95s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.86s/it]\n",
            "                   all         62        104    0.00342      0.542     0.0498     0.0121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     16/499         0G    0.08861    0.01784    0.03472         29        640: 100% 4/4 [01:31<00:00, 22.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.25s/it]\n",
            "                   all         62        104     0.0395      0.385     0.0649     0.0149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     17/499         0G    0.08477     0.0221    0.03148         40        640: 100% 4/4 [01:32<00:00, 23.12s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.43s/it]\n",
            "                   all         62        104      0.318     0.0795     0.0667     0.0134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     18/499         0G    0.08369    0.01834    0.03003         31        640: 100% 4/4 [01:34<00:00, 23.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.56s/it]\n",
            "                   all         62        104      0.322      0.114     0.0727     0.0189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     19/499         0G    0.08333    0.02164    0.02918         38        640: 100% 4/4 [01:32<00:00, 23.21s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.11s/it]\n",
            "                   all         62        104      0.323      0.176      0.118     0.0302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     20/499         0G    0.07992    0.01929    0.03167         37        640: 100% 4/4 [01:33<00:00, 23.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.38s/it]\n",
            "                   all         62        104      0.334       0.16      0.105     0.0326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     21/499         0G    0.08458    0.01878    0.03146         36        640: 100% 4/4 [01:31<00:00, 22.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.04s/it]\n",
            "                   all         62        104      0.327      0.287      0.137      0.052\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     22/499         0G    0.08262    0.01918    0.03224         40        640: 100% 4/4 [01:32<00:00, 23.10s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.57s/it]\n",
            "                   all         62        104      0.579      0.142     0.0936     0.0341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     23/499         0G    0.08368    0.01918    0.02816         52        640: 100% 4/4 [01:34<00:00, 23.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.75s/it]\n",
            "                   all         62        104      0.541      0.148     0.0426     0.0125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     24/499         0G    0.08559    0.01704    0.02882         41        640: 100% 4/4 [01:31<00:00, 22.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.37s/it]\n",
            "                   all         62        104      0.545      0.134     0.0439     0.0103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     25/499         0G    0.08272    0.01911    0.02742         37        640: 100% 4/4 [01:30<00:00, 22.56s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.23s/it]\n",
            "                   all         62        104       0.27     0.0953      0.015      0.003\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     26/499         0G    0.08403     0.0155    0.02927         43        640: 100% 4/4 [01:31<00:00, 22.99s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.86s/it]\n",
            "                   all         62        104      0.556      0.131     0.0575     0.0154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     27/499         0G     0.0827    0.01668    0.02713         37        640: 100% 4/4 [01:31<00:00, 22.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.30s/it]\n",
            "                   all         62        104      0.337      0.167      0.073     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     28/499         0G    0.08372    0.01757    0.02568         41        640: 100% 4/4 [01:30<00:00, 22.72s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:21<00:00, 10.69s/it]\n",
            "                   all         62        104      0.334      0.204     0.0785     0.0279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     29/499         0G     0.0815    0.01653    0.02606         36        640: 100% 4/4 [01:30<00:00, 22.68s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.66s/it]\n",
            "                   all         62        104       0.71      0.236      0.218     0.0892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     30/499         0G    0.07597    0.02022    0.02665         38        640: 100% 4/4 [01:31<00:00, 22.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.18s/it]\n",
            "                   all         62        104      0.331      0.262      0.075     0.0258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     31/499         0G    0.08131    0.01519    0.02566         32        640: 100% 4/4 [01:30<00:00, 22.69s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.17s/it]\n",
            "                   all         62        104      0.567     0.0668     0.0454     0.0115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     32/499         0G    0.08003    0.01406    0.02425         36        640: 100% 4/4 [01:33<00:00, 23.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.51s/it]\n",
            "                   all         62        104     0.0645       0.24     0.0791     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     33/499         0G    0.08039    0.01679    0.02284         45        640: 100% 4/4 [01:32<00:00, 23.06s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.48s/it]\n",
            "                   all         62        104      0.459      0.188      0.206     0.0987\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     34/499         0G    0.06716    0.01988    0.02658         48        640: 100% 4/4 [01:30<00:00, 22.68s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.21s/it]\n",
            "                   all         62        104      0.379      0.227      0.138     0.0353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     35/499         0G    0.06812     0.0178    0.02598         39        640: 100% 4/4 [01:31<00:00, 22.94s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.40s/it]\n",
            "                   all         62        104      0.419      0.268      0.217     0.0737\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     36/499         0G    0.06638    0.01809    0.02227         44        640: 100% 4/4 [01:32<00:00, 23.18s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.51s/it]\n",
            "                   all         62        104      0.693       0.27      0.208     0.0853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     37/499         0G    0.05969    0.01574    0.02148         31        640: 100% 4/4 [01:35<00:00, 23.82s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:19<00:00,  9.75s/it]\n",
            "                   all         62        104      0.694      0.262      0.197     0.0583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     38/499         0G    0.06906    0.01708    0.02213         40        640: 100% 4/4 [01:35<00:00, 23.99s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:20<00:00, 10.34s/it]\n",
            "                   all         62        104      0.695      0.237      0.242        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     39/499         0G    0.05766    0.01664    0.02329         47        640: 100% 4/4 [01:31<00:00, 22.75s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.42s/it]\n",
            "                   all         62        104      0.108      0.463      0.139     0.0344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     40/499         0G    0.06231    0.01605    0.02176         36        640: 100% 4/4 [01:37<00:00, 24.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:18<00:00,  9.39s/it]\n",
            "                   all         62        104      0.726      0.333      0.291      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "     41/499         0G    0.06171    0.01637    0.02069         36        640:  50% 2/4 [00:48<00:47, 23.93s/it]"
          ]
        }
      ],
      "source": [
        "!cd yolov5 && python train.py --img 640 --batch 16 --epochs 500 --data cien_images_señales.yaml --weights yolov5s.pt  --workers 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2kD7s0Byc_4"
      },
      "outputs": [],
      "source": [
        "# LOGGER.info(( '%10s ' * 7) % ('Epoch', 'gpu_mem', 'box', 'obJ', 'cls', 'labels', 'img_size'))\n",
        "# if RANK in [-1, 0]:\n",
        "#     pbar = tqdm(pbar, total=nb, bar_format='{1_bar}{bar:10}{r_bar}{bar:-10b}') #progress_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Swu5AxSyc_4"
      },
      "source": [
        "***\n",
        "**`Cargamos nuestro modelo`**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jngefhm7yc_4"
      },
      "outputs": [],
      "source": [
        "modelo_100_señales = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp10/weights/best.pt', force_reload=True)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "eb4177ad35f1696ea836e1658e5ab8a4373538db1d3c5cdb2fa9c2e3e3ef954b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}